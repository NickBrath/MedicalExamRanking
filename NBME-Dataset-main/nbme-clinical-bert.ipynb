{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T10:31:56.330889Z",
     "iopub.status.busy": "2022-10-06T10:31:56.330339Z",
     "iopub.status.idle": "2022-10-06T10:32:02.892112Z",
     "shell.execute_reply": "2022-10-06T10:32:02.891334Z",
     "shell.execute_reply.started": "2022-10-06T10:31:56.330780Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import tokenizers\n",
    "import torch.nn as nn\n",
    "import torch \n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm.auto import tqdm \n",
    "from ast import literal_eval\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoModel , AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T10:32:02.894006Z",
     "iopub.status.busy": "2022-10-06T10:32:02.893740Z",
     "iopub.status.idle": "2022-10-06T10:32:15.964656Z",
     "shell.execute_reply": "2022-10-06T10:32:15.963842Z",
     "shell.execute_reply.started": "2022-10-06T10:32:02.893972Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de02400d3074b1d88fd370674dc17c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/321 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b814c2fac3645c1bf14f6fa342df1bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3409f3cc7ae4949a80a98efd3a2c79c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8f04b401794f17ba4fe95d40d652f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class config:\n",
    "    MAX_LEN = 312\n",
    "    TRAIN_BATCH_SIZE = 32\n",
    "    VALID_BATCH_SIZE = 16 \n",
    "    EPOCHS = 2\n",
    "    model = \"Tsubasaz/clinical-bert-base-128\" # pretrained model on clinical notes \n",
    "    MODEL_PATH = \"model.bin\"\n",
    "    TOKENIZER = AutoTokenizer.from_pretrained(model)\n",
    "    DROPOUT = 0.2\n",
    "    MAX_GRAD_NORM = 1.0\n",
    "    LEARNING_RATE = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T10:32:15.966256Z",
     "iopub.status.busy": "2022-10-06T10:32:15.966005Z",
     "iopub.status.idle": "2022-10-06T10:32:16.699196Z",
     "shell.execute_reply": "2022-10-06T10:32:16.698433Z",
     "shell.execute_reply.started": "2022-10-06T10:32:15.966222Z"
    }
   },
   "outputs": [],
   "source": [
    "BASE_PATH = \"../input/nbme-score-clinical-patient-notes/\"\n",
    "features_df = pd.read_csv(BASE_PATH + \"features.csv\")\n",
    "patient_notes_df = pd.read_csv(BASE_PATH + \"patient_notes.csv\")\n",
    "train_df = pd.read_csv(BASE_PATH + \"train.csv\")\n",
    "test_df = pd.read_csv(BASE_PATH + \"test.csv\")\n",
    "submission_df = pd.read_csv(BASE_PATH + \"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T10:32:16.701531Z",
     "iopub.status.busy": "2022-10-06T10:32:16.701259Z",
     "iopub.status.idle": "2022-10-06T10:32:16.747497Z",
     "shell.execute_reply": "2022-10-06T10:32:16.746814Z",
     "shell.execute_reply.started": "2022-10-06T10:32:16.701496Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_text</th>\n",
       "      <th>pn_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00016_000</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>['dad with recent heart attcak']</td>\n",
       "      <td>['696 724']</td>\n",
       "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00016_001</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>['mom with \"thyroid disease']</td>\n",
       "      <td>['668 693']</td>\n",
       "      <td>Family-history-of-thyroid-disorder</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00016_002</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>['chest pressure']</td>\n",
       "      <td>['203 217']</td>\n",
       "      <td>Chest-pressure</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00016_003</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>['intermittent episodes', 'episode']</td>\n",
       "      <td>['70 91', '176 183']</td>\n",
       "      <td>Intermittent-symptoms</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00016_004</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>['felt as if he were going to pass out']</td>\n",
       "      <td>['222 258']</td>\n",
       "      <td>Lightheaded</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  case_num  pn_num  feature_num  \\\n",
       "0  00016_000         0      16            0   \n",
       "1  00016_001         0      16            1   \n",
       "2  00016_002         0      16            2   \n",
       "3  00016_003         0      16            3   \n",
       "4  00016_004         0      16            4   \n",
       "\n",
       "                                 annotation              location  \\\n",
       "0          ['dad with recent heart attcak']           ['696 724']   \n",
       "1             ['mom with \"thyroid disease']           ['668 693']   \n",
       "2                        ['chest pressure']           ['203 217']   \n",
       "3      ['intermittent episodes', 'episode']  ['70 91', '176 183']   \n",
       "4  ['felt as if he were going to pass out']           ['222 258']   \n",
       "\n",
       "                                        feature_text  \\\n",
       "0  Family-history-of-MI-OR-Family-history-of-myoc...   \n",
       "1                 Family-history-of-thyroid-disorder   \n",
       "2                                     Chest-pressure   \n",
       "3                              Intermittent-symptoms   \n",
       "4                                        Lightheaded   \n",
       "\n",
       "                                          pn_history  \n",
       "0  HPI: 17yo M presents with palpitations. Patien...  \n",
       "1  HPI: 17yo M presents with palpitations. Patien...  \n",
       "2  HPI: 17yo M presents with palpitations. Patien...  \n",
       "3  HPI: 17yo M presents with palpitations. Patien...  \n",
       "4  HPI: 17yo M presents with palpitations. Patien...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(train_df, features_df, on=['feature_num','case_num'], how='inner')\n",
    "df =pd.merge(df, patient_notes_df, on=['pn_num','case_num'], how='inner')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T10:32:16.748809Z",
     "iopub.status.busy": "2022-10-06T10:32:16.748561Z",
     "iopub.status.idle": "2022-10-06T10:32:16.752787Z",
     "shell.execute_reply": "2022-10-06T10:32:16.752140Z",
     "shell.execute_reply.started": "2022-10-06T10:32:16.748772Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_info_columns\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T10:32:16.754728Z",
     "iopub.status.busy": "2022-10-06T10:32:16.754297Z",
     "iopub.status.idle": "2022-10-06T10:32:16.763618Z",
     "shell.execute_reply": "2022-10-06T10:32:16.762908Z",
     "shell.execute_reply.started": "2022-10-06T10:32:16.754692Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00016_000', 0, 16, 0, \"['dad with recent heart attcak']\",\n",
       "       \"['696 724']\",\n",
       "       'Family-history-of-MI-OR-Family-history-of-myocardial-infarction',\n",
       "       'HPI: 17yo M presents with palpitations. Patient reports 3-4 months of intermittent episodes of \"heart beating/pounding out of my chest.\" 2 days ago during a soccer game had an episode, but this time had chest pressure and felt as if he were going to pass out (did not lose conciousness). Of note patient endorses abusing adderall, primarily to study (1-3 times per week). Before recent soccer game, took adderrall night before and morning of game. Denies shortness of breath, diaphoresis, fevers, chills, headache, fatigue, changes in sleep, changes in vision/hearing, abdominal paun, changes in bowel or urinary habits. \\r\\nPMHx: none\\r\\nRx: uses friends adderrall\\r\\nFHx: mom with \"thyroid disease,\" dad with recent heart attcak\\r\\nAll: none\\r\\nImmunizations: up to date\\r\\nSHx: Freshmen in college. Endorses 3-4 drinks 3 nights / week (on weekends), denies tabacco, endorses trying marijuana. Sexually active with girlfriend x 1 year, uses condoms'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T10:32:16.765340Z",
     "iopub.status.busy": "2022-10-06T10:32:16.765051Z",
     "iopub.status.idle": "2022-10-06T10:32:16.972649Z",
     "shell.execute_reply": "2022-10-06T10:32:16.971942Z",
     "shell.execute_reply.started": "2022-10-06T10:32:16.765297Z"
    }
   },
   "outputs": [],
   "source": [
    "# always use literal_eval instead of eval https://nedbatchelder.com/blog/201206/eval_really_is_dangerous.html\n",
    "df[\"annotation\"] = [literal_eval(x) for x in df[\"annotation\"]] \n",
    "df[\"location\"] = [literal_eval(x) for x in df[\"location\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T10:32:16.974041Z",
     "iopub.status.busy": "2022-10-06T10:32:16.973763Z",
     "iopub.status.idle": "2022-10-06T10:32:26.338032Z",
     "shell.execute_reply": "2022-10-06T10:32:26.337271Z",
     "shell.execute_reply.started": "2022-10-06T10:32:16.974008Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed5505b0f2941b7bd23ccdb3b1c23a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pn_history max(lengths): 280\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aef47bf7d217400386472ff616a89198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_text  max(lengths): 29\n",
      "max_len: 312\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pn_history_lengths = []\n",
    "tk0 = tqdm(df['pn_history'].fillna(\"\").values, total=len(df))\n",
    "for text in tk0:\n",
    "    length = config.TOKENIZER.encode(text,add_special_tokens=False)\n",
    "        \n",
    "    pn_history_lengths.append(len(length))\n",
    "print(f'pn_history max(lengths): {max(pn_history_lengths)}')\n",
    "\n",
    "\n",
    "features_lengths=[]\n",
    "tk1 = tqdm(df['feature_text'].fillna(\"\").values, total=len(df))\n",
    "for text in tk1:\n",
    "    length = config.TOKENIZER.encode(text,add_special_tokens=False)\n",
    "    features_lengths.append(len(length))\n",
    "print(f'feature_text  max(lengths): {max(features_lengths)}')\n",
    "\n",
    "max_lenght= max(pn_history_lengths) + max(features_lengths) + 3 # cls & sep & sep\n",
    "print(f\"max_len: {max_lenght}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T10:32:26.339684Z",
     "iopub.status.busy": "2022-10-06T10:32:26.339422Z",
     "iopub.status.idle": "2022-10-06T10:32:26.344429Z",
     "shell.execute_reply": "2022-10-06T10:32:26.343448Z",
     "shell.execute_reply.started": "2022-10-06T10:32:26.339650Z"
    }
   },
   "outputs": [],
   "source": [
    "def loc_list_to_ints(loc_list):\n",
    "    to_return = []\n",
    "    for loc_str in loc_list:  \n",
    "        loc_strs = loc_str.split(\";\")\n",
    "        for loc in loc_strs:\n",
    "            start, end = loc.split()\n",
    "            to_return.append((int(start), int(end)))\n",
    "    return to_return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T10:32:26.348163Z",
     "iopub.status.busy": "2022-10-06T10:32:26.347623Z",
     "iopub.status.idle": "2022-10-06T10:32:26.362044Z",
     "shell.execute_reply": "2022-10-06T10:32:26.361290Z",
     "shell.execute_reply.started": "2022-10-06T10:32:26.348128Z"
    }
   },
   "outputs": [],
   "source": [
    "def classLabeling(pn_history, feature_text, annotation, location, tokenizer, max_len):    ##X , Y, selected_text  \n",
    "    \n",
    "\n",
    "    location_list = loc_list_to_ints(location)   # convert the locations into a list \n",
    "\n",
    "    char_targets = [0] * len(pn_history)  # creation of character taragert you can reason below \n",
    "\n",
    "    for loc,anno in zip(location_list ,annotation):        \n",
    "        \n",
    "        len_st = int(loc[1]) - int(loc[0])\n",
    "        idx0 = None\n",
    "        idx1 = None        \n",
    "        for ind in (i for i, e in enumerate(pn_history) if (e == anno[0] and i == int(loc[0]))): # Only if the annotation start with character we are interested and look and character annotation postion match go inside the loop\n",
    "        \n",
    "            if pn_history[ind: ind+len_st] == anno.strip():\n",
    "\n",
    "                idx0 = ind\n",
    "                idx1 = ind + len_st - 1\n",
    "                if idx0 != None and idx1 != None:\n",
    "                    for ct in range(idx0, idx1 + 1): # make character targets as \"1\" for them \n",
    "                        char_targets[ct] = 1 \n",
    "                break\n",
    "    # Tokenize the data and here we are returing the offstes which we gone use as labels which you can find below \n",
    "    tokenized_input = config.TOKENIZER.encode_plus(feature_text,pn_history,return_attention_mask=True,\n",
    "                                                  return_offsets_mapping=True,return_token_type_ids=True)\n",
    "    \n",
    "    input_ids = tokenized_input['input_ids']\n",
    "    mask = tokenized_input['attention_mask']\n",
    "    token_type_ids = tokenized_input['token_type_ids']\n",
    "    offsets = tokenized_input['offset_mapping']\n",
    "    \n",
    "    target_idx = []\n",
    "    for j, (offset1, offset2) in enumerate(offsets): # look for offsets \n",
    "        if sum(char_targets[offset1: offset2]) > 0: # if the lenght of the char_target for particualr target is greater than 0 then added one at that offsets \n",
    "            target_idx.append(j)\n",
    "            \n",
    "    #padding\n",
    "    padding_length = config.MAX_LEN - len(input_ids) # Since we used 312 as max_lenght incase if we less lenght we need to pad the zeros \n",
    "    if padding_length > 0:\n",
    "        input_ids = input_ids + ([0] * padding_length)\n",
    "        mask = mask + ([0] * padding_length)\n",
    "        token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "        offsets = offsets + ([(0, 0)] * padding_length)\n",
    "       \n",
    "    #creating label\n",
    "    ignore_idxes = np.where(np.array(token_type_ids) != 1)[0] # Bascially we use token type ids Segment token indices to indicate first and second portions of the input\n",
    "\n",
    "    label = np.zeros(len(offsets))\n",
    "    label[ignore_idxes] = 0.0 # creating a labels zero for not interested to look \n",
    "    label[target_idx] = 1.0  # label for which we are interested to look\n",
    "    return {\n",
    "    'ids': input_ids,\n",
    "    'mask': mask,\n",
    "    'token_type_ids': token_type_ids,\n",
    "    'labels': label,\n",
    "    'offsets': offsets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T10:32:26.363555Z",
     "iopub.status.busy": "2022-10-06T10:32:26.363297Z",
     "iopub.status.idle": "2022-10-06T10:32:26.374303Z",
     "shell.execute_reply": "2022-10-06T10:32:26.373480Z",
     "shell.execute_reply.started": "2022-10-06T10:32:26.363521Z"
    }
   },
   "outputs": [],
   "source": [
    "class NBMEDataset:\n",
    "    \n",
    "    def __init__(self,pn_history,feature_text, annotation, location):\n",
    "        self.pn_history=pn_history\n",
    "        self.feature_text=feature_text\n",
    "        self.annotation=annotation\n",
    "        self.location=location\n",
    "    def __len__(self):\n",
    "        return len(self.pn_history+self.feature_text)\n",
    "    \n",
    "    def __getitem__(self,item):\n",
    "   \n",
    "        output=classLabeling(self.pn_history[item],self.feature_text[item],self.annotation[item],self.location[item],config.TOKENIZER,config.MAX_LEN)\n",
    "        \n",
    "        return {\n",
    "            'input_ids':torch.tensor(output['ids']),\n",
    "             'mask':torch.tensor(output['mask'],dtype=torch.long),\n",
    "            'token_type_ids':torch.tensor(output['token_type_ids'],dtype=torch.long),\n",
    "            'labels':torch.tensor(output['labels'],dtype=torch.float),\n",
    "            'offsets':torch.tensor(output['offsets'],dtype=torch.long)   \n",
    "            \n",
    "        }\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T10:32:26.375815Z",
     "iopub.status.busy": "2022-10-06T10:32:26.375499Z",
     "iopub.status.idle": "2022-10-06T10:32:26.386231Z",
     "shell.execute_reply": "2022-10-06T10:32:26.385451Z",
     "shell.execute_reply.started": "2022-10-06T10:32:26.375773Z"
    }
   },
   "outputs": [],
   "source": [
    "class NBMEModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NBMEModel,self).__init__()\n",
    "        self.bert=AutoModel.from_pretrained(config.model)\n",
    "        self.dropout=nn.Dropout(0.4)\n",
    "        self.linear=nn.Linear(768,1)\n",
    "        self.parameter=nn.Parameter(torch.ones(1))\n",
    "    def forward(self,ids, mask,token_ids):\n",
    "        sequence_output=self.bert(ids,attention_mask=mask, token_type_ids=token_ids)[0] # we gone take last hidden state no the model \n",
    "        output=self.dropout(sequence_output)\n",
    "        logits=self.linear(output)\n",
    "        logits = logits.squeeze(-1) \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T10:32:26.387963Z",
     "iopub.status.busy": "2022-10-06T10:32:26.387677Z",
     "iopub.status.idle": "2022-10-06T10:32:26.394671Z",
     "shell.execute_reply": "2022-10-06T10:32:26.394072Z",
     "shell.execute_reply.started": "2022-10-06T10:32:26.387914Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_fn(logits, labels):\n",
    "    loss_fct = torch.nn.BCEWithLogitsLoss(reduction = \"mean\")\n",
    "    loss = loss_fct(logits,labels.float())\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T10:32:26.396673Z",
     "iopub.status.busy": "2022-10-06T10:32:26.395818Z",
     "iopub.status.idle": "2022-10-06T10:32:26.452986Z",
     "shell.execute_reply": "2022-10-06T10:32:26.452259Z",
     "shell.execute_reply.started": "2022-10-06T10:32:26.396637Z"
    }
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T10:32:26.454731Z",
     "iopub.status.busy": "2022-10-06T10:32:26.454213Z",
     "iopub.status.idle": "2022-10-06T10:33:00.075150Z",
     "shell.execute_reply": "2022-10-06T10:33:00.074454Z",
     "shell.execute_reply.started": "2022-10-06T10:32:26.454686Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cecdf83ea7d34e5aa619defd23a8f7fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/712 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929a53ce5bd3455c8e97e71ba3b00f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/418M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Tsubasaz/clinical-bert-base-128 were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at Tsubasaz/clinical-bert-base-128 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model=NBMEModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T10:33:00.076753Z",
     "iopub.status.busy": "2022-10-06T10:33:00.076424Z",
     "iopub.status.idle": "2022-10-06T10:33:05.076827Z",
     "shell.execute_reply": "2022-10-06T10:33:05.076121Z",
     "shell.execute_reply.started": "2022-10-06T10:33:00.076717Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NBMEModel(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       "  (linear): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T10:33:05.078491Z",
     "iopub.status.busy": "2022-10-06T10:33:05.078243Z",
     "iopub.status.idle": "2022-10-06T10:33:05.105667Z",
     "shell.execute_reply": "2022-10-06T10:33:05.104967Z",
     "shell.execute_reply.started": "2022-10-06T10:33:05.078457Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_fn(dataloader,model,optimizer,scheduler=None):\n",
    "    model.train()\n",
    "    \n",
    "    train_loss=0\n",
    "\n",
    "\n",
    "    tqd=tqdm(dataloader,total=len(dataloader))\n",
    "    \n",
    "    for batch , data in enumerate(tqd):\n",
    "\n",
    "      \n",
    "        ids=data['input_ids']\n",
    "        mask=data['mask']\n",
    "        token_ids=data['token_type_ids']\n",
    "        label=data['labels']\n",
    "        offsets=data['offsets']\n",
    "        \n",
    "        ids=ids.to(DEVICE,dtype=torch.long)\n",
    "        mask=mask.to(DEVICE,dtype=torch.long)\n",
    "        token_ids=token_ids.to(DEVICE,dtype=torch.long)\n",
    "        label=label.to(DEVICE,dtype=torch.long)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        output=model(ids=ids,mask=mask,token_ids=token_ids)\n",
    "        \n",
    "        loss=loss_fn(output,label)\n",
    "\n",
    "        train_loss=+loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # cliping to get rid of exploding gradient if any \n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "    return train_loss/len(dataloader)\n",
    "        \n",
    "        \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T10:33:05.107830Z",
     "iopub.status.busy": "2022-10-06T10:33:05.107276Z",
     "iopub.status.idle": "2022-10-06T10:33:05.758969Z",
     "shell.execute_reply": "2022-10-06T10:33:05.757988Z",
     "shell.execute_reply.started": "2022-10-06T10:33:05.107793Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_fn(dataloader, model):\n",
    "    model.eval()\n",
    "    \n",
    "        \n",
    "    eval_loss=0\n",
    "    \n",
    "    tk = tqdm(dataloader, total=len(dataloader)) \n",
    "    \n",
    "    for batch, data in enumerate(tk):\n",
    "        ids = data['input_ids']\n",
    "        token_type_ids = data[\"token_type_ids\"]\n",
    "        mask = data[\"mask\"]\n",
    "        labels = data['labels']\n",
    "        offsets = data[\"offsets\"]\n",
    "        ids = ids.to(DEVICE, dtype=torch.long)\n",
    "        token_type_ids = token_type_ids.to(DEVICE, dtype=torch.long)\n",
    "        mask = mask.to(DEVICE, dtype=torch.long)\n",
    "        labels = labels.to(DEVICE, dtype=torch.float64)\n",
    "      \n",
    "\n",
    "        logits = model(ids=ids, mask=mask, token_ids=token_type_ids ) #last_hidden_state\n",
    "            \n",
    "        loss = loss_fn(logits, labels)\n",
    " \n",
    "        eval_loss=+loss.item()\n",
    "         \n",
    "    \n",
    "        \n",
    "    return eval_loss/len(dataloader)\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T10:33:05.761137Z",
     "iopub.status.busy": "2022-10-06T10:33:05.760622Z",
     "iopub.status.idle": "2022-10-06T10:33:05.773894Z",
     "shell.execute_reply": "2022-10-06T10:33:05.773101Z",
     "shell.execute_reply.started": "2022-10-06T10:33:05.761100Z"
    }
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    \n",
    "    train_loss_data, valid_loss_data = [], []\n",
    "    \n",
    "  \n",
    "    df_train , df_valid= train_test_split(df,test_size=0.3, random_state=42)\n",
    "   \n",
    "    df_train = df_train.reset_index(drop=True) \n",
    "    df_valid = df_valid.reset_index(drop=True)\n",
    "    \n",
    "    train_dataset = NBMEDataset(\n",
    "        pn_history=df_train.pn_history.values,\n",
    "        feature_text=df_train.feature_text.values,\n",
    "        annotation=df_train.annotation.values,\n",
    "        location=df_train.location.values\n",
    "        \n",
    "    )\n",
    "    \n",
    "    train_data_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.TRAIN_BATCH_SIZE\n",
    " \n",
    "    )\n",
    "    \n",
    "   \n",
    "\n",
    "    valid_dataset = NBMEDataset(\n",
    "        pn_history=df_valid.pn_history.values,\n",
    "        feature_text=df_valid.feature_text.values,\n",
    "        annotation=df_valid.annotation.values,\n",
    "        location=df_valid.location.values\n",
    "    )\n",
    "\n",
    "    valid_data_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=config.VALID_BATCH_SIZE\n",
    "    )\n",
    "\n",
    "\n",
    "    \n",
    "    num_train_steps = int(len(df_train) / config.TRAIN_BATCH_SIZE * config.EPOCHS)\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_parameters, lr=config.LEARNING_RATE)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps=0, \n",
    "        num_training_steps=num_train_steps\n",
    "    )\n",
    "\n",
    "\n",
    "    for i in range(config.EPOCHS):\n",
    "        print(\"Epoch: {}/{}\".format(i + 1, config.EPOCHS))\n",
    "    \n",
    "      \n",
    "\n",
    "        train_loss = train_fn(train_data_loader, model, optimizer, scheduler=scheduler)\n",
    "        \n",
    "        eval_loss =  eval_fn(valid_data_loader , model )\n",
    "       \n",
    "        print(f\"Train loss: {train_loss} and the valida loss {eval_loss} after the epochs : {i+1}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T10:33:05.775888Z",
     "iopub.status.busy": "2022-10-06T10:33:05.775410Z",
     "iopub.status.idle": "2022-10-06T10:45:07.410615Z",
     "shell.execute_reply": "2022-10-06T10:45:07.409880Z",
     "shell.execute_reply.started": "2022-10-06T10:33:05.775844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd1e8f05c5a4a1893061235c855e12b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d57bdd0703443797a9e5141c5e18bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/269 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 7.189687091512041e-05 and the valida loss 9.498140708886115e-05 after the epochs : 1\n",
      "Epoch: 2/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec6d4b765b7464eb35527a0dd5aac79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda7b682c528487b8e6d9a9a49467e8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/269 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 6.756610787524202e-05 and the valida loss 9.507552260138288e-05 after the epochs : 2\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T10:45:07.412681Z",
     "iopub.status.busy": "2022-10-06T10:45:07.412262Z",
     "iopub.status.idle": "2022-10-06T10:45:07.428803Z",
     "shell.execute_reply": "2022-10-06T10:45:07.428169Z",
     "shell.execute_reply.started": "2022-10-06T10:45:07.412643Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(BASE_PATH + \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T10:45:07.430320Z",
     "iopub.status.busy": "2022-10-06T10:45:07.430066Z",
     "iopub.status.idle": "2022-10-06T10:45:07.448087Z",
     "shell.execute_reply": "2022-10-06T10:45:07.447425Z",
     "shell.execute_reply.started": "2022-10-06T10:45:07.430278Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = pd.merge(test_df, features_df, on=['feature_num','case_num'], how='inner')\n",
    "df_test =pd.merge(df_test, patient_notes_df, on=['pn_num','case_num'], how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T10:45:07.449520Z",
     "iopub.status.busy": "2022-10-06T10:45:07.449135Z",
     "iopub.status.idle": "2022-10-06T10:45:07.460589Z",
     "shell.execute_reply": "2022-10-06T10:45:07.459833Z",
     "shell.execute_reply.started": "2022-10-06T10:45:07.449484Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>feature_text</th>\n",
       "      <th>pn_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00016_000</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00016_001</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>Family-history-of-thyroid-disorder</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00016_002</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>Chest-pressure</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00016_003</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>Intermittent-symptoms</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00016_004</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>Lightheaded</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  case_num  pn_num  feature_num  \\\n",
       "0  00016_000         0      16            0   \n",
       "1  00016_001         0      16            1   \n",
       "2  00016_002         0      16            2   \n",
       "3  00016_003         0      16            3   \n",
       "4  00016_004         0      16            4   \n",
       "\n",
       "                                        feature_text  \\\n",
       "0  Family-history-of-MI-OR-Family-history-of-myoc...   \n",
       "1                 Family-history-of-thyroid-disorder   \n",
       "2                                     Chest-pressure   \n",
       "3                              Intermittent-symptoms   \n",
       "4                                        Lightheaded   \n",
       "\n",
       "                                          pn_history  \n",
       "0  HPI: 17yo M presents with palpitations. Patien...  \n",
       "1  HPI: 17yo M presents with palpitations. Patien...  \n",
       "2  HPI: 17yo M presents with palpitations. Patien...  \n",
       "3  HPI: 17yo M presents with palpitations. Patien...  \n",
       "4  HPI: 17yo M presents with palpitations. Patien...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T10:45:07.462112Z",
     "iopub.status.busy": "2022-10-06T10:45:07.461847Z",
     "iopub.status.idle": "2022-10-06T10:45:07.470564Z",
     "shell.execute_reply": "2022-10-06T10:45:07.469855Z",
     "shell.execute_reply.started": "2022-10-06T10:45:07.462078Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inferece on one of the data point request \n",
    "@torch.no_grad()\n",
    "def inference_fn(df_test, model, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "\n",
    "    tokenized_input = config.TOKENIZER.encode_plus(df_test[0],df_test[1],return_attention_mask=True,padding='max_length',truncation=True,\n",
    "                                                return_offsets_mapping=True,return_token_type_ids=True,max_length=config.MAX_LEN)\n",
    "        \n",
    "    input_ids = torch.tensor(tokenized_input['input_ids'],dtype=torch.long).unsqueeze(0)\n",
    "    mask = torch.tensor(tokenized_input['attention_mask'],dtype=torch.long).unsqueeze(0)\n",
    "    token_type_ids = torch.tensor(tokenized_input['token_type_ids'],dtype=torch.long).unsqueeze(0)\n",
    "    offsets = tokenized_input['offset_mapping']\n",
    "        \n",
    "        \n",
    "    input_ids= input_ids.to(DEVICE)\n",
    "    mask=mask.to(DEVICE)\n",
    "    token_type_ids = token_type_ids.to(DEVICE)\n",
    "    \n",
    "    y_preds= model(input_ids,mask,token_type_ids)\n",
    "    \n",
    "    predictions= y_preds.sigmoid().to('cpu').numpy()\n",
    "    \n",
    "        \n",
    "    return predictions, offsets\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T10:45:07.472313Z",
     "iopub.status.busy": "2022-10-06T10:45:07.471842Z",
     "iopub.status.idle": "2022-10-06T10:45:07.503290Z",
     "shell.execute_reply": "2022-10-06T10:45:07.502370Z",
     "shell.execute_reply.started": "2022-10-06T10:45:07.472271Z"
    }
   },
   "outputs": [],
   "source": [
    "data,offsets=inference_fn(df_test.iloc[1,4:6],model,DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T10:45:07.504771Z",
     "iopub.status.busy": "2022-10-06T10:45:07.504518Z",
     "iopub.status.idle": "2022-10-06T10:45:07.511209Z",
     "shell.execute_reply": "2022-10-06T10:45:07.510265Z",
     "shell.execute_reply.started": "2022-10-06T10:45:07.504739Z"
    }
   },
   "outputs": [],
   "source": [
    "index_ofstring = np.where(data[0] >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T10:45:07.512613Z",
     "iopub.status.busy": "2022-10-06T10:45:07.512428Z",
     "iopub.status.idle": "2022-10-06T10:45:07.521840Z",
     "shell.execute_reply": "2022-10-06T10:45:07.520962Z",
     "shell.execute_reply.started": "2022-10-06T10:45:07.512591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Family-history-of-thyroid-disorder',\n",
       "       'HPI: 17yo M presents with palpitations. Patient reports 3-4 months of intermittent episodes of \"heart beating/pounding out of my chest.\" 2 days ago during a soccer game had an episode, but this time had chest pressure and felt as if he were going to pass out (did not lose conciousness). Of note patient endorses abusing adderall, primarily to study (1-3 times per week). Before recent soccer game, took adderrall night before and morning of game. Denies shortness of breath, diaphoresis, fevers, chills, headache, fatigue, changes in sleep, changes in vision/hearing, abdominal paun, changes in bowel or urinary habits. \\r\\nPMHx: none\\r\\nRx: uses friends adderrall\\r\\nFHx: mom with \"thyroid disease,\" dad with recent heart attcak\\r\\nAll: none\\r\\nImmunizations: up to date\\r\\nSHx: Freshmen in college. Endorses 3-4 drinks 3 nights / week (on weekends), denies tabacco, endorses trying marijuana. Sexually active with girlfriend x 1 year, uses condoms'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.iloc[1,4:6].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T10:45:07.526288Z",
     "iopub.status.busy": "2022-10-06T10:45:07.526046Z",
     "iopub.status.idle": "2022-10-06T10:45:07.530511Z",
     "shell.execute_reply": "2022-10-06T10:45:07.529593Z",
     "shell.execute_reply.started": "2022-10-06T10:45:07.526248Z"
    }
   },
   "outputs": [],
   "source": [
    "# lets made it offsets \n",
    "\n",
    "begning_of_string = offsets[187][0]\n",
    "end_of_string = offsets[188][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T10:45:07.532203Z",
     "iopub.status.busy": "2022-10-06T10:45:07.531749Z",
     "iopub.status.idle": "2022-10-06T10:45:07.541180Z",
     "shell.execute_reply": "2022-10-06T10:45:07.540420Z",
     "shell.execute_reply.started": "2022-10-06T10:45:07.532168Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thyroid disease'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model is doing good its able to predict properly \n",
    "df_test.iloc[1,5][begning_of_string:end_of_string]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
